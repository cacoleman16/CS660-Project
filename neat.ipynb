{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neat.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPKnd1kKWy57AyA6wkcYpdu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cacoleman16/CS660-Project/blob/main/neat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QS3b3GnGkxaE"
      },
      "source": [
        "\n",
        "import numpy as np  # pip install numpy\n",
        "import cv2          # pip install opencv-python\n",
        "import neat         # pip install neat-python\n",
        "import pickle       # pip install cloudpickle\n",
        "from envWrapper import make_env\n",
        "import gym_super_mario_bros\n",
        "\n",
        "\n",
        "class Worker(object):\n",
        "\n",
        "\n",
        "    def init_values(self):\n",
        "        self.counter = 0\n",
        "        self.score = 0\n",
        "        self.xpos = 0\n",
        "        self.xpos_max = 0\n",
        "        self.stage = 0\n",
        "        self.lives = 3\n",
        "    def _get_actions(self, actions):\n",
        "\n",
        "        return np.random.choice(np.flatnonzero(actions == actions.max()))\n",
        "\n",
        "\n",
        "    def update_fitness(self, info, reward, fitness_current):\n",
        "        right = 0\n",
        "        if info['status'] != 'small':\n",
        "            bonus = 100\n",
        "        else:\n",
        "            bonus = 0\n",
        "\n",
        "        if self.stage == info['stage'] and self.xpos <= info['x_pos']:\n",
        "            fitness_current -= 5\n",
        "\n",
        "        \n",
        "        # reward = 0 \n",
        "\n",
        "        if self.lives > info['life'] or  info['life'] == 255:\n",
        "            reward = -150\n",
        "\n",
        "        if (self.stage != info['stage']) and self.score != 0:\n",
        "              bonus += 300\n",
        "\n",
        "\n",
        "        self.xpos = info['x_pos']\n",
        "        self.stage = info['stage']\n",
        "        self.lives = info['life'] \n",
        "\n",
        "\n",
        "        if self.xpos > self.xpos_max:\n",
        "            right = 10\n",
        "            self.xpos_max = self.xpos\n",
        "\n",
        "        fitness_current += ( info['score'] - self.score)  + reward + right + bonus\n",
        "        self.score = info['score']\n",
        "\n",
        "        return fitness_current\n",
        "        \n",
        "\n",
        "    def eval_genomes(self, genomes, config):\n",
        "\n",
        "\n",
        "        for genome_id, genome in genomes:\n",
        "\n",
        "            self.init_values()\n",
        "        \n",
        "            self.env =  gym_super_mario_bros.make('SuperMarioBros-v0')\n",
        "            self.env =  make_env(self.env)\n",
        "            state = self.env.reset()\n",
        "            \n",
        "\n",
        "            done = False\n",
        "            fitness = 0\n",
        "            old = 0\n",
        "            current_max_fitness = 0\n",
        "            net = neat.nn.RecurrentNetwork.create(genome, config)\n",
        "            while not done:\n",
        "                state = cv2.resize(state, None, fx=0.5, fy=0.5)\n",
        "                nnOutput = net.activate(state.flatten())\n",
        "                actions = np.array(nnOutput)\n",
        "                action = self._get_actions(actions)\n",
        "                nextState, reward, done, info = self.env.step(action)\n",
        "                # self.env.render()\n",
        "                fitness = self.update_fitness(info, reward, fitness)\n",
        "                state = nextState\n",
        "                self.counter += 1\n",
        "                if self.counter % 50 == 0:\n",
        "                    if (old == self.xpos) & (self.level == info['stage']):\n",
        "                        done = True \n",
        "                    else:\n",
        "                        old = self.xpos\n",
        "\n",
        "                self.level = info['stage']\n",
        "                if fitness  > current_max_fitness:\n",
        "                    current_max_fitness = fitness \n",
        "                    self.counter = 0\n",
        "         \n",
        "                \n",
        "                # if done or self.counter == 250:\n",
        "                #     done = True\n",
        "                #     print(genome_id, fitness)\n",
        "\n",
        "\n",
        "            genome.fitness = current_max_fitness\n",
        "            self.env.close()\n",
        "            # print(genome, fitness)\n",
        "            \n",
        "config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
        "                     neat.DefaultSpeciesSet, neat.DefaultStagnation,\n",
        "                     'config')\n",
        "\n",
        "p = neat.Population(config)\n",
        "\n",
        "\n",
        "p.add_reporter(neat.StdOutReporter(True))\n",
        "stats = neat.StatisticsReporter()\n",
        "p.add_reporter(stats)\n",
        "p.add_reporter(neat.Checkpointer(10))\n",
        "worker = Worker()\n",
        "winner = p.run(worker.eval_genomes, 1000)\n",
        "\n",
        "with open('winnerNEW.pkl', 'wb') as output:\n",
        "    pickle.dump(winner, output, 1)\n",
        "    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxnB0F8Jk4k4"
      },
      "source": [
        "from nes_py.wrappers import JoypadSpace\n",
        "import gym_super_mario_bros\n",
        "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT, COMPLEX_MOVEMENT\n",
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "import collections\n",
        "import gym\n",
        "\n",
        "\n",
        "class MaxAndSkipEnv(gym.Wrapper):\n",
        "    def __init__(self, env=None, skip=4):\n",
        "        \"\"\"Return only every `skip`-th frame\"\"\"\n",
        "        super(MaxAndSkipEnv, self).__init__(env)\n",
        "        # most recent raw observations (for max pooling across time steps)\n",
        "        self._obs_buffer = collections.deque(maxlen=2)\n",
        "        self._skip = skip\n",
        "\n",
        "    def step(self, action):\n",
        "        total_reward = 0.0\n",
        "        done = None\n",
        "        for _ in range(self._skip):\n",
        "            obs, reward, done, info = self.env.step(action)\n",
        "            self._obs_buffer.append(obs)\n",
        "            total_reward += reward\n",
        "            if done:\n",
        "                break\n",
        "        max_frame = np.max(np.stack(self._obs_buffer), axis=0)\n",
        "        return max_frame, total_reward, done, info\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Clear past frame buffer and init to first obs\"\"\"\n",
        "        self._obs_buffer.clear()\n",
        "        obs = self.env.reset()\n",
        "        self._obs_buffer.append(obs)\n",
        "        return obs\n",
        "\n",
        "\n",
        "class ProcessFrame84(gym.ObservationWrapper):\n",
        "    \"\"\"\n",
        "    Downsamples image to 84x84\n",
        "    Greyscales image\n",
        "\n",
        "    Returns numpy array\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, env=None):\n",
        "        super(ProcessFrame84, self).__init__(env)\n",
        "        self.observation_space = gym.spaces.Box(\n",
        "            low=0, high=255, shape=(84, 84, 1), dtype=np.uint8)\n",
        "\n",
        "    def observation(self, obs):\n",
        "        return ProcessFrame84.process(obs)\n",
        "\n",
        "    @staticmethod\n",
        "    def process(frame):\n",
        "        if frame.size == 240 * 256 * 3:\n",
        "            img = np.reshape(frame, [240, 256, 3]).astype(np.float32)\n",
        "        else:\n",
        "            assert False, \"Unknown resolution.\"\n",
        "        img = img[:, :, 0] * 0.299 + img[:, :, 1] * \\\n",
        "            0.587 + img[:, :, 2] * 0.114\n",
        "        resized_screen = cv2.resize(\n",
        "            img, (84, 110), interpolation=cv2.INTER_AREA)\n",
        "        x_t = resized_screen[18:102, :]\n",
        "        x_t = np.reshape(x_t, [84, 84, 1])\n",
        "        return x_t.astype(np.uint8)\n",
        "\n",
        "\n",
        "class ImageToPyTorch(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super(ImageToPyTorch, self).__init__(env)\n",
        "        old_shape = self.observation_space.shape\n",
        "        self.observation_space = gym.spaces.Box(low=0.0, high=1.0, shape=(old_shape[-1], old_shape[0], old_shape[1]),\n",
        "                                                dtype=np.float32)\n",
        "\n",
        "    def observation(self, observation):\n",
        "        return np.moveaxis(observation, 2, 0)\n",
        "\n",
        "\n",
        "class ScaledFloatFrame(gym.ObservationWrapper):\n",
        "    \"\"\"Normalize pixel values in frame --> 0 to 1\"\"\"\n",
        "\n",
        "    def observation(self, obs):\n",
        "        return np.array(obs).astype(np.float32) / 255.0\n",
        "\n",
        "\n",
        "class BufferWrapper(gym.ObservationWrapper):\n",
        "    def __init__(self, env, n_steps, dtype=np.float32):\n",
        "        super(BufferWrapper, self).__init__(env)\n",
        "        self.dtype = dtype\n",
        "        old_space = env.observation_space\n",
        "        self.observation_space = gym.spaces.Box(old_space.low.repeat(n_steps, axis=0),\n",
        "                                                old_space.high.repeat(n_steps, axis=0), dtype=dtype)\n",
        "\n",
        "    def reset(self):\n",
        "        self.buffer = np.zeros_like(\n",
        "            self.observation_space.low, dtype=self.dtype)\n",
        "        return self.observation(self.env.reset())\n",
        "\n",
        "    def observation(self, observation):\n",
        "        self.buffer[:-1] = self.buffer[1:]\n",
        "        self.buffer[-1] = observation\n",
        "        return self.buffer\n",
        "\n",
        "\n",
        "def make_env(env):\n",
        "    env = MaxAndSkipEnv(env)\n",
        "    env = ProcessFrame84(env)\n",
        "    env = ImageToPyTorch(env)\n",
        "    env = BufferWrapper(env, 4)\n",
        "    env = ScaledFloatFrame(env)\n",
        "    return JoypadSpace(env, SIMPLE_MOVEMENT)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z62qQPAQk5Ij"
      },
      "source": [
        "## the conif file \n",
        "\n",
        "\n",
        "[NEAT]\n",
        "fitness_criterion     = max\n",
        "fitness_threshold     = 1000000000000\n",
        "pop_size              = 100\n",
        "reset_on_extinction   = True\n",
        "\n",
        "[DefaultGenome]\n",
        "# node activation options\n",
        "activation_default      = relu\n",
        "activation_mutate_rate  = 0.04\n",
        "activation_options      = sigmoid\n",
        "\n",
        "# node aggregation options\n",
        "aggregation_default     = sum\n",
        "aggregation_mutate_rate = 0.3\n",
        "aggregation_options     = sum\n",
        "\n",
        "# node bias options\n",
        "bias_init_mean          = 0.0\n",
        "bias_init_stdev         = 1.0\n",
        "bias_max_value          = 30.0\n",
        "bias_min_value          = -30.0\n",
        "bias_mutate_power       = 2.093\n",
        "bias_mutate_rate        = 0.0509\n",
        "bias_replace_rate       = 0.1\n",
        "\n",
        "# genome compatibility options\n",
        "compatibility_disjoint_coefficient = 2.0\n",
        "compatibility_weight_coefficient   = 0.5\n",
        "\n",
        "# connection add/remove rates\n",
        "conn_add_prob           = 0.988\n",
        "conn_delete_prob        = 0.146\n",
        "\n",
        "# connection enable options\n",
        "enabled_default         = True\n",
        "enabled_mutate_rate     = 0.01\n",
        "\n",
        "feed_forward            = True\n",
        "initial_connection      = unconnected\n",
        "\n",
        "# node add/remove rates\n",
        "node_add_prob           = 0.25\n",
        "node_delete_prob        = 0.1\n",
        "\n",
        "# network parameters\n",
        "num_hidden              = 4\n",
        "num_inputs              =  7056\n",
        "num_outputs             = 7\n",
        "\n",
        "# node response options\n",
        "response_init_mean      = 1.0\n",
        "response_init_stdev     = 0.0\n",
        "response_max_value      = 30.0\n",
        "response_min_value      = -30.0\n",
        "response_mutate_power   = 0.1\n",
        "response_mutate_rate    = 0.1\n",
        "response_replace_rate   = 0.0\n",
        "\n",
        "# connection weight options\n",
        "weight_init_mean        = 0.0\n",
        "weight_init_stdev       = 1.0\n",
        "weight_max_value        = 30\n",
        "weight_min_value        = -30\n",
        "weight_mutate_power     = 0.825\n",
        "weight_mutate_rate      = 0.460\n",
        "weight_replace_rate     = 0.0245\n",
        "\n",
        "[DefaultSpeciesSet]\n",
        "compatibility_threshold = 2.5\n",
        "\n",
        "[DefaultStagnation]\n",
        "species_fitness_func = mean\n",
        "max_stagnation       = 10\n",
        "species_elitism      = 2\n",
        "\n",
        "[DefaultReproduction]\n",
        "elitism            = 2\n",
        "survival_threshold = 0.1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}